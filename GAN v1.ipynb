{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25\n",
    "\n",
    "# Model params\n",
    "g_input_size = 1     # Random noise dimension coming into generator, per output vector\n",
    "g_hidden_size = 50   # Generator complexity\n",
    "g_output_size = 1    # size of generated output vector\n",
    "d_input_size = 100   # Minibatch size - cardinality of distributions\n",
    "d_hidden_size = 50   # Discriminator complexity\n",
    "d_output_size = 1    # Single dimension for 'real' vs. 'fake'\n",
    "minibatch_size = d_input_size\n",
    "\n",
    "d_learning_rate = 2e-4  # 2e-4\n",
    "g_learning_rate = 2e-4\n",
    "optim_betas = (0.9, 0.999)\n",
    "num_epochs = 30000\n",
    "print_interval = 200\n",
    "d_steps = 1  # 'k' steps in the original GAN paper. Can put the discriminator on higher training freq than generator\n",
    "g_steps = 1\n",
    "\n",
    "# ### Uncomment only one of these\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Data and variances]\n"
     ]
    }
   ],
   "source": [
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n",
    "\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=d_learning_rate, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=g_learning_rate, betas=optim_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: D: 0.8460698127746582/0.5943595767021179 G: 0.813252866268158 (Real: [3.9521866011619569, 1.1685733866570043], Fake: [-0.48025260657072066, 0.0070735080882127618]) \n",
      "200: D: 0.010584743693470955/0.23989149928092957 G: 1.5469396114349365 (Real: [3.8880642449855802, 1.3031401983026045], Fake: [0.48656365692615511, 0.029472201957884633]) \n",
      "400: D: 0.01170569472014904/0.1212318018078804 G: 2.165919780731201 (Real: [4.0753459572792057, 1.1031088556396209], Fake: [0.48296793580055236, 0.065159438157828584]) \n",
      "600: D: 0.04766295477747917/0.05856797844171524 G: 2.85894775390625 (Real: [4.052794470787048, 1.1097557495287973], Fake: [0.56469883948564525, 0.19945158076355821]) \n",
      "800: D: 0.005996947176754475/0.07891087979078293 G: 2.874392509460449 (Real: [3.8947348964214323, 1.1025138207848162], Fake: [0.79311690978705884, 0.4237904713837935]) \n",
      "1000: D: 0.0009975639404729009/0.16946099698543549 G: 3.50296688079834 (Real: [3.8404748439788818, 1.3049847662925498], Fake: [1.3054529586806893, 0.95077784296421708]) \n",
      "1200: D: 0.1726532280445099/0.765688955783844 G: 0.6997259259223938 (Real: [3.8803380224108697, 1.2597204217816671], Fake: [3.6241414135694505, 1.0955707060425364]) \n",
      "1400: D: 0.28620806336402893/0.35352593660354614 G: 0.3565662205219269 (Real: [4.1461720307171346, 1.1491502832967702], Fake: [4.7522781682014461, 1.0472643207503562]) \n",
      "1600: D: 0.9517347812652588/0.47927138209342957 G: 0.7406931519508362 (Real: [3.990002701282501, 1.1507992273229064], Fake: [4.9688773608207706, 1.2745542584411953]) \n",
      "1800: D: 1.2301671504974365/1.1505742073059082 G: 0.8881396055221558 (Real: [3.7186012506484984, 1.2669751707569101], Fake: [4.7999551022052769, 1.6212906352779177]) \n",
      "2000: D: 0.8647657632827759/0.35150641202926636 G: 1.4599348306655884 (Real: [4.0817821824550631, 1.2912176376242195], Fake: [5.2789268922805785, 1.100152725956465]) \n",
      "2200: D: 0.7263297438621521/0.3458193838596344 G: 1.0864956378936768 (Real: [4.0219802688062192, 1.4131084946756465], Fake: [4.6603008735179898, 1.5505001102563625]) \n",
      "2400: D: 0.4885936677455902/0.46088340878486633 G: 0.7114943861961365 (Real: [3.9989857310056687, 1.2414090610555626], Fake: [4.6850144028663632, 1.1505426806031254]) \n",
      "2600: D: 0.5771848559379578/0.8823745250701904 G: 0.5332812666893005 (Real: [4.1106348973512645, 1.2219537857845417], Fake: [3.6548575997352599, 1.3615371006212982]) \n",
      "2800: D: 0.6574892997741699/0.7669846415519714 G: 0.4699358344078064 (Real: [4.0010707139968869, 1.3529050190818461], Fake: [3.537624499797821, 1.1655651759336658]) \n",
      "3000: D: 0.5201934576034546/0.7868281006813049 G: 0.6325590014457703 (Real: [4.0347139680385586, 1.1796322944608804], Fake: [3.189881059527397, 1.2384722923282343]) \n",
      "3200: D: 0.7406212091445923/0.36747583746910095 G: 0.9388892650604248 (Real: [3.9860244548320769, 1.1709499803039836], Fake: [3.7625766682624815, 1.2072213175577955]) \n",
      "3400: D: 0.9967359304428101/0.8047866821289062 G: 0.8099247813224792 (Real: [3.9999251258373261, 1.1915109476752552], Fake: [4.1752424621582032, 1.4066121832470768]) \n",
      "3600: D: 0.7290958762168884/0.4777437150478363 G: 0.9652920365333557 (Real: [4.1976956188678738, 1.3043483913278613], Fake: [4.6775011909008022, 1.358086937187251]) \n",
      "3800: D: 0.8190638422966003/0.5717917084693909 G: 0.7324272990226746 (Real: [4.0585402846336365, 1.2664747431498737], Fake: [4.2858001112937929, 1.2575807596614057]) \n",
      "4000: D: 0.647599458694458/0.5502608418464661 G: 0.9429811835289001 (Real: [4.0505479681491856, 1.2434373749216727], Fake: [3.5309173285961153, 1.3372328217922991]) \n",
      "4200: D: 0.6473382115364075/0.503978431224823 G: 0.6381120085716248 (Real: [3.9262982204556467, 1.1538716760964947], Fake: [3.8619089746475219, 1.0328792470087627]) \n",
      "4400: D: 0.3094591498374939/0.8083325624465942 G: 0.8187701106071472 (Real: [4.035283939689398, 1.3267534794861935], Fake: [3.9371441030502319, 1.1435183613715809]) \n",
      "4600: D: 0.9134846925735474/0.696018397808075 G: 1.1429284811019897 (Real: [3.9655182398483158, 1.1825292987181413], Fake: [4.3019455063343051, 1.3586675680310978]) \n",
      "4800: D: 0.8199086785316467/0.7393888235092163 G: 0.6412056088447571 (Real: [3.8625733464956284, 1.3635898447315968], Fake: [4.2412897729873658, 1.127968826059438]) \n",
      "5000: D: 0.5048660039901733/0.6844790577888489 G: 0.7188594341278076 (Real: [4.0738738399744037, 1.2105137746433492], Fake: [3.9171656036376952, 1.079165336147264]) \n",
      "5200: D: 0.5134851932525635/0.6996058821678162 G: 0.5202715992927551 (Real: [3.867671784758568, 1.0950622979953712], Fake: [3.9103942525386812, 1.1796287463929009]) \n",
      "5400: D: 0.7211261987686157/0.5221695899963379 G: 0.8398128747940063 (Real: [3.9609040689468382, 1.1771304712993143], Fake: [4.1768686115741733, 1.198310292489559]) \n",
      "5600: D: 0.6628832221031189/0.5884846448898315 G: 0.8054194450378418 (Real: [4.1845298409461975, 1.1072894286095336], Fake: [3.7287857949733736, 1.2839169638213306]) \n",
      "5800: D: 0.9079979062080383/0.3128933012485504 G: 1.0871399641036987 (Real: [4.0678269797563553, 1.2621557634440019], Fake: [3.8556553161144258, 1.3046560627089379]) \n",
      "6000: D: 0.59085613489151/0.7564404606819153 G: 0.6012845039367676 (Real: [3.8256536173820495, 1.1455355929409305], Fake: [3.9577863168716432, 1.2981705807575805]) \n",
      "6200: D: 0.6892725229263306/0.8088768720626831 G: 0.9344117641448975 (Real: [3.9497785449028013, 1.1546418238183249], Fake: [4.081176633834839, 1.2557066275848494]) \n",
      "6400: D: 0.7945035099983215/0.5040937662124634 G: 0.8550624847412109 (Real: [4.058637900054455, 1.1623243651620097], Fake: [4.0262793731689452, 1.1571168816439221]) \n",
      "6600: D: 0.9058027267456055/0.5529802441596985 G: 0.6318531632423401 (Real: [3.8692142724990846, 1.3107833804458782], Fake: [4.0372385048866271, 1.1865361750678389]) \n",
      "6800: D: 0.6138530969619751/0.515699565410614 G: 0.8347316384315491 (Real: [4.1917206835746761, 1.1941744934235332], Fake: [3.8993088918924332, 1.3209816173106366]) \n",
      "7000: D: 0.38314008712768555/0.599647045135498 G: 0.6710909008979797 (Real: [3.990934422016144, 1.3093416294746267], Fake: [3.8234455275535582, 1.2730161746883721]) \n",
      "7200: D: 0.6016761660575867/0.6205535531044006 G: 0.7346979379653931 (Real: [3.8647313886880874, 1.23211162269157], Fake: [3.6309863895177843, 1.3708968449850938]) \n",
      "7400: D: 0.6778977513313293/0.7767536640167236 G: 0.8129259347915649 (Real: [4.1937403374910351, 1.2715865499254704], Fake: [4.0578918004035947, 1.0663813153481048]) \n",
      "7600: D: 0.5570178627967834/0.7429960370063782 G: 0.917927622795105 (Real: [4.0221458423137664, 1.1477481793104458], Fake: [4.0900797688961026, 1.2781925467808271]) \n",
      "7800: D: 0.6644395589828491/0.6307627558708191 G: 0.8823987245559692 (Real: [4.1100066816806793, 1.1398042147025391], Fake: [4.0357370054721828, 1.0884023311827706]) \n",
      "8000: D: 0.5733442902565002/0.49938368797302246 G: 0.7310034036636353 (Real: [3.9887687942385672, 1.2926195891397401], Fake: [4.1804795724153516, 1.2967801186793204]) \n",
      "8200: D: 0.26064708828926086/0.684309720993042 G: 0.6669319868087769 (Real: [3.9907014107704164, 1.1166752053981122], Fake: [4.13995512008667, 1.0885152113209304]) \n",
      "8400: D: 0.232662633061409/1.051969051361084 G: 0.8567931056022644 (Real: [4.0014981621503827, 1.3526087791198214], Fake: [3.9874747008085252, 1.2614684547672657]) \n",
      "8600: D: 0.4590270221233368/0.5371919870376587 G: 0.587144672870636 (Real: [4.2311638954281809, 1.2858451930212735], Fake: [3.9364741969108583, 1.2073908737145034]) \n",
      "8800: D: 0.97755366563797/0.6472128629684448 G: 0.7606958150863647 (Real: [4.0368267416954042, 1.168620742669505], Fake: [4.2048444712162016, 1.165576429313899]) \n",
      "9000: D: 0.9214003682136536/0.8927868008613586 G: 0.754403829574585 (Real: [3.9813228145241739, 1.1056618959471634], Fake: [3.7404656749963761, 1.2445829490404763]) \n",
      "9200: D: 0.6496242880821228/0.6752722859382629 G: 0.9815242290496826 (Real: [4.0162666666507718, 1.2034374200068862], Fake: [4.0462337815761567, 1.2716457082979196]) \n",
      "9400: D: 0.48817121982574463/0.6507352590560913 G: 0.7306733727455139 (Real: [4.0417496344447139, 1.4925814229795977], Fake: [4.0306689167022709, 1.1003985272505055]) \n",
      "9600: D: 0.470261812210083/0.6122754216194153 G: 0.7089941501617432 (Real: [4.1146130207180978, 1.4062099182664205], Fake: [4.2443717485666275, 1.133604722390833]) \n",
      "9800: D: 0.7330924272537231/0.5249752998352051 G: 0.7104354500770569 (Real: [4.0618012511730193, 1.1837099389003167], Fake: [3.9426302695274353, 1.2587601131786597]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000: D: 0.977918803691864/0.6114557981491089 G: 0.7739893794059753 (Real: [3.9476002049446106, 1.2074999923630061], Fake: [4.0048085027933125, 1.338086053606151]) \n",
      "10200: D: 0.8323512077331543/0.5435066223144531 G: 1.0546272993087769 (Real: [4.0780276829004292, 1.2168515767545938], Fake: [3.9539078521728515, 1.0627023436737408]) \n",
      "10400: D: 0.5068973898887634/0.3478733003139496 G: 0.6366167068481445 (Real: [3.8530531804263592, 1.2614667597477862], Fake: [3.9821322321891786, 1.4585048001342096]) \n",
      "10600: D: 0.5325584411621094/0.46303293108940125 G: 1.7383157014846802 (Real: [3.9648299539089202, 1.2399059782174002], Fake: [4.060488053560257, 1.1730191072188487]) \n",
      "10800: D: 0.6437920331954956/0.5035157799720764 G: 0.9933136701583862 (Real: [4.1032256758213039, 1.1671453504601785], Fake: [4.1737215477228169, 1.2012757545519264]) \n",
      "11000: D: 0.42675310373306274/0.5508109331130981 G: 1.0152722597122192 (Real: [3.8773564541339876, 1.1895635232595614], Fake: [3.8669850456714632, 1.240022615429381]) \n",
      "11200: D: 0.758359968662262/0.5053423047065735 G: 0.8262704610824585 (Real: [3.8571255373954774, 1.1131653468164204], Fake: [4.259936474561691, 1.2192272977604357]) \n",
      "11400: D: 0.8721303343772888/0.5732508897781372 G: 0.5014371871948242 (Real: [3.7847726511955262, 1.1756437418267014], Fake: [3.9271876263618468, 1.3823559268363363]) \n",
      "11600: D: 0.36080026626586914/0.9388411045074463 G: 1.5635141134262085 (Real: [3.8630088591575622, 1.2271134773072534], Fake: [3.9324855798482896, 1.1638820414719575]) \n",
      "11800: D: 0.6964495182037354/0.49463048577308655 G: 0.6044114828109741 (Real: [4.21969021320343, 1.1020698000006031], Fake: [4.0479375588893891, 1.2571796391021353]) \n",
      "12000: D: 0.30488672852516174/1.3305343389511108 G: 0.5064107775688171 (Real: [4.0128770637512208, 1.2771039384239702], Fake: [4.2943044006824493, 1.2757631577805781]) \n",
      "12200: D: 0.7765436768531799/0.2697359323501587 G: 1.5297825336456299 (Real: [3.9280816960334777, 1.2921738723506733], Fake: [4.2674486780166623, 1.358776874553135]) \n",
      "12400: D: 0.7511343359947205/0.9263867735862732 G: 1.403809905052185 (Real: [4.0280608451366424, 1.1767084120359297], Fake: [3.9711432576179506, 1.3403175587303078]) \n",
      "12600: D: 0.6164103150367737/1.016791820526123 G: 0.8622456192970276 (Real: [3.994130861759186, 1.1805040703270926], Fake: [3.8696103787422178, 1.2569659930898669]) \n",
      "12800: D: 0.2270011305809021/0.6379077434539795 G: 1.1474401950836182 (Real: [3.9973028409481048, 1.2968108071110556], Fake: [3.873710440993309, 1.2290608924019988]) \n",
      "13000: D: 0.20747020840644836/0.8878772258758545 G: 0.8882237076759338 (Real: [4.093272901773453, 1.3021128297601416], Fake: [4.1466633373498913, 1.3389926361981535]) \n",
      "13200: D: 0.28808024525642395/0.6402385234832764 G: 0.5518818497657776 (Real: [4.0789733760058882, 1.2061424514479191], Fake: [4.2122979032993317, 1.3342415282421398]) \n",
      "13400: D: 0.9283119440078735/0.2785937190055847 G: 1.4794126749038696 (Real: [3.9629693770408632, 1.1057867978257776], Fake: [4.1425274813175204, 1.1591450546282631]) \n",
      "13600: D: 0.6274154186248779/0.5106155872344971 G: 1.2843166589736938 (Real: [4.0491091382503512, 1.049593341854532], Fake: [4.1507339584827427, 1.2657141620031014]) \n",
      "13800: D: 0.8627362251281738/0.14342090487480164 G: 0.41983169317245483 (Real: [3.8772878986597061, 1.0782034452348328], Fake: [4.1441742670536037, 0.99700857461524106]) \n",
      "14000: D: 0.09438971430063248/0.6258861422538757 G: 0.3849371373653412 (Real: [3.9948597201704978, 1.3669699818490313], Fake: [3.94471125125885, 1.2718107955802176]) \n",
      "14200: D: 0.7602731585502625/0.6385782957077026 G: 0.9045608639717102 (Real: [4.0231916213035586, 1.2380618336497189], Fake: [4.1129138171672821, 1.1725519199011343]) \n",
      "14400: D: 0.6711350083351135/0.42028364539146423 G: 1.1645992994308472 (Real: [3.7882186955213548, 1.4355579070913858], Fake: [3.867319265604019, 1.2345212148372284]) \n",
      "14600: D: 0.22824324667453766/0.4318143129348755 G: 0.5965762138366699 (Real: [3.9530103987455369, 1.0801443755441793], Fake: [3.9582456398010253, 1.0768020828478606]) \n",
      "14800: D: 0.394627183675766/0.20867124199867249 G: 1.6205395460128784 (Real: [3.8676219069957734, 1.175127933863477], Fake: [3.9933150231838228, 1.1540804860528902]) \n",
      "15000: D: 0.5730332136154175/1.2362315654754639 G: 1.270058035850525 (Real: [4.0813619446754457, 1.3081626552578161], Fake: [4.2183914184570313, 1.3129397624797352]) \n",
      "15200: D: 0.6241323947906494/0.7082424163818359 G: 1.584512710571289 (Real: [4.0995536154508594, 1.2462295685573095], Fake: [4.0982584917545317, 1.366969928142419]) \n",
      "15400: D: 1.6586087942123413/0.5625597834587097 G: 1.5406159162521362 (Real: [4.0927734345197679, 1.3715568117548518], Fake: [4.0089437055587771, 1.2604183318673057]) \n",
      "15600: D: 0.5817440748214722/0.616847813129425 G: 1.3093231916427612 (Real: [3.8886732053756714, 1.1586066730287947], Fake: [4.0446430146694183, 1.2292711459946597]) \n",
      "15800: D: 0.7987650036811829/0.49364832043647766 G: 0.7017021179199219 (Real: [4.1446486616134646, 1.1478650120214324], Fake: [3.8681625163555147, 1.1879628436842693]) \n",
      "16000: D: 0.9141625761985779/0.13922205567359924 G: 1.2112035751342773 (Real: [3.9019311699271202, 1.1637406007752016], Fake: [4.1780946648120878, 1.1182654010487674]) \n",
      "16200: D: 0.38323575258255005/0.5918756723403931 G: 0.4029655158519745 (Real: [3.9001210927963257, 1.1260246797953672], Fake: [4.1729994034767151, 1.2015156959819373]) \n",
      "16400: D: 0.021341297775506973/0.6293541193008423 G: 1.325775146484375 (Real: [3.906305128931999, 1.2810174214121981], Fake: [3.8202499246597288, 1.2715160463354547]) \n",
      "16600: D: 0.7683004140853882/0.7621968388557434 G: 2.273393154144287 (Real: [4.101899390220642, 1.1330470530064154], Fake: [3.9729851281642912, 1.265477277395884]) \n",
      "16800: D: 0.014574240893125534/0.048759087920188904 G: 0.8153727054595947 (Real: [3.9125471365451814, 1.3416866285944515], Fake: [3.7602550619840622, 1.5181519368197309]) \n",
      "17000: D: 0.15189293026924133/0.47768333554267883 G: 2.728607416152954 (Real: [3.7447826802730559, 1.3479277334455451], Fake: [4.1661949801445006, 1.248993320737618]) \n",
      "17200: D: 0.49916955828666687/0.373372882604599 G: 1.278518557548523 (Real: [3.8821900928020479, 1.1458935741017104], Fake: [4.1648874294757841, 1.2114451407349158]) \n",
      "17400: D: 0.27989575266838074/0.16377077996730804 G: 1.5349370241165161 (Real: [4.0281664639711376, 1.316043264243256], Fake: [3.9168537735939024, 1.1773072534322466]) \n",
      "17600: D: 0.1746644824743271/0.6373665928840637 G: 1.9998016357421875 (Real: [4.1198629119992258, 1.2351425865499612], Fake: [3.9273347902297973, 1.3287293555828017]) \n",
      "17800: D: 0.0721307322382927/0.36728543043136597 G: 1.3543474674224854 (Real: [3.8862722992897032, 1.2086357074078808], Fake: [4.0957332003116607, 1.1211658558092166]) \n",
      "18000: D: 0.08488041162490845/1.815632939338684 G: 0.19562967121601105 (Real: [3.9270206081867216, 1.2066744335718234], Fake: [3.86136478304863, 1.269128471395695]) \n",
      "18200: D: 0.16227006912231445/0.06703759729862213 G: 1.4605828523635864 (Real: [4.1926088035106659, 1.0066938946864024], Fake: [4.1624515426158908, 1.0389117670708179]) \n",
      "18400: D: 0.7872173190116882/0.8744858503341675 G: 1.2451368570327759 (Real: [3.8863217806816102, 1.3305128829458934], Fake: [4.0305169594287875, 1.1909369492845203]) \n",
      "18600: D: 0.48888441920280457/0.11640437692403793 G: 2.230982780456543 (Real: [4.2615457752346995, 1.3923995090095154], Fake: [4.2866503465175629, 1.240660214150191]) \n",
      "18800: D: 0.940566897392273/0.3939530849456787 G: 1.4066177606582642 (Real: [4.0535621750354771, 1.2123081778142084], Fake: [3.8146217364072799, 1.3840335789174789]) \n",
      "19000: D: 0.971041202545166/0.15762527287006378 G: 2.0091164112091064 (Real: [4.1877716475725171, 1.196238982615524], Fake: [3.8934420251846316, 1.3342343643269579]) \n",
      "19200: D: 0.10289561748504639/0.1535835862159729 G: 1.9566524028778076 (Real: [3.81873102247715, 1.4201231518850288], Fake: [4.3175753641128543, 1.1892572480244314]) \n",
      "19400: D: 0.18454749882221222/0.140262633562088 G: 2.501971483230591 (Real: [4.0036724793910983, 1.1171259848123332], Fake: [4.012561814188957, 1.2532594475352132]) \n",
      "19600: D: 0.9134578704833984/0.0879560112953186 G: 1.1555957794189453 (Real: [3.8895779848098755, 1.0638793508947322], Fake: [4.0522617352008821, 1.2267992730795645]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19800: D: 0.07039639353752136/0.2768682837486267 G: 0.9615154266357422 (Real: [4.1379947936534878, 1.2100385606994994], Fake: [4.3604865014553074, 1.2507012790237906]) \n",
      "20000: D: 0.5961591601371765/0.07158263027667999 G: 1.5370358228683472 (Real: [3.9547063088417054, 1.3284698806316206], Fake: [4.1566352355480198, 1.230018501840062]) \n",
      "20200: D: 0.0005776762263849378/0.10584354400634766 G: 2.0180163383483887 (Real: [4.0141260910034182, 1.3362087487636503], Fake: [3.9344013535976412, 1.305578022792699]) \n",
      "20400: D: 1.4720218181610107/0.11203619837760925 G: 1.4525229930877686 (Real: [4.083313555717468, 1.2401686177512399], Fake: [4.24296635389328, 1.1287874351016316]) \n",
      "20600: D: 0.064852774143219/0.3406282067298889 G: 2.3255927562713623 (Real: [4.0159021782875062, 1.2846850916581454], Fake: [4.0977309095859527, 1.1508431761155871]) \n",
      "20800: D: 0.12489984929561615/0.07633918523788452 G: 1.0566996335983276 (Real: [4.0571343487501146, 1.1251583803834062], Fake: [4.1039616334438325, 1.1547475292447014]) \n",
      "21000: D: 0.182255357503891/0.10926507413387299 G: 1.822048544883728 (Real: [3.9454902863502501, 1.2188379086918824], Fake: [4.144904195070267, 1.3573254011955542]) \n",
      "21200: D: 1.1669689416885376/1.1540277004241943 G: 1.5119291543960571 (Real: [4.0688834726810459, 1.2322044279657554], Fake: [4.4443322765827178, 1.319488542860592]) \n",
      "21400: D: 0.5392266511917114/0.35473403334617615 G: 1.590307354927063 (Real: [3.8158756846189501, 1.2047785860779632], Fake: [4.0973650419712069, 1.3121479394904456]) \n",
      "21600: D: 0.6083107590675354/0.3606036305427551 G: 1.6967095136642456 (Real: [4.0805579362809654, 1.1760240323412277], Fake: [3.7502759057283401, 1.2845325414450834]) \n",
      "21800: D: 0.0410689115524292/0.34937843680381775 G: 0.5975596904754639 (Real: [4.1089770174026485, 1.2195585886675664], Fake: [3.8970694231986998, 1.1764669302377897]) \n",
      "22000: D: 0.014092031866312027/1.765466570854187 G: 1.4489842653274536 (Real: [3.771866376399994, 1.2650045212735646], Fake: [4.2539777588844299, 1.2951796219591081]) \n",
      "22200: D: 0.8375834822654724/0.15251424908638 G: 1.2667102813720703 (Real: [3.8766179412603377, 1.1901921658475549], Fake: [4.7941535902023311, 1.1605262632897877]) \n",
      "22400: D: 0.34087827801704407/0.10237614065408707 G: 0.7954656481742859 (Real: [3.9640566274523734, 1.2085478206156923], Fake: [3.9332120752334596, 1.4240614045692104]) \n",
      "22600: D: 2.1490280628204346/0.25012901425361633 G: 0.5493298172950745 (Real: [4.1561489534378051, 1.1436993936195425], Fake: [3.9235306572914124, 1.316355139584956]) \n",
      "22800: D: 0.2528620958328247/0.3800636827945709 G: 0.39343419671058655 (Real: [3.8501381635665894, 1.2469325938399021], Fake: [3.5637962472438813, 1.1565118338607434]) \n",
      "23000: D: 0.24255865812301636/0.9196301698684692 G: 1.3203905820846558 (Real: [4.0723099660873414, 1.191457172503642], Fake: [4.0234301626682285, 1.0408619875079665]) \n",
      "23200: D: 1.2097007036209106/1.2108064889907837 G: 1.2098112106323242 (Real: [3.9216212439537048, 1.2883122687993371], Fake: [5.0287490260601047, 1.2767736664525646]) \n",
      "23400: D: 1.1486986875534058/0.03487234190106392 G: 3.6485579013824463 (Real: [3.7575513821840287, 1.4114992192763898], Fake: [5.5853683853149416, 1.4980182035081142]) \n",
      "23600: D: 0.5678147077560425/0.3292334973812103 G: 0.2364017218351364 (Real: [4.0983644223213194, 1.2855252089943794], Fake: [3.9968971550464629, 1.3038729272923764]) \n",
      "23800: D: 0.37745970487594604/0.8947692513465881 G: 1.6022381782531738 (Real: [3.9947194695472716, 1.2816912495078177], Fake: [3.1688583729136734, 1.0530047319243376]) \n",
      "24000: D: 0.16636328399181366/0.3842184841632843 G: 0.9879978895187378 (Real: [3.8181136131286619, 1.3410226662066673], Fake: [4.8788513422012327, 1.3555113762697193]) \n",
      "24200: D: 0.07141297310590744/0.5358787178993225 G: 1.1374633312225342 (Real: [4.0254903805255893, 1.2317630155585495], Fake: [5.7674728631973267, 1.7259316593282636]) \n",
      "24400: D: 0.2792677879333496/0.03426184132695198 G: 2.999094009399414 (Real: [3.9289173340797423, 1.1209726452098383], Fake: [6.4924070692062381, 1.5040180931344223]) \n",
      "24600: D: 0.03682872653007507/0.20440161228179932 G: 3.697134494781494 (Real: [3.8687014532089234, 1.2080829307334864], Fake: [6.0620948207378387, 1.7084713455247744]) \n",
      "24800: D: 1.0244051218032837/0.6543716192245483 G: 0.7126956582069397 (Real: [4.1970736765861512, 1.2265850355669117], Fake: [3.9143792268633844, 1.2540094851368899]) \n",
      "25000: D: 0.13076017796993256/0.2406274676322937 G: 0.17170338332653046 (Real: [4.2355298554897312, 1.2981918945599247], Fake: [3.4819596186280251, 1.0389187185770132]) \n",
      "25200: D: 0.97697913646698/0.3094256520271301 G: 0.6413010358810425 (Real: [3.9041194164752961, 1.2692467134283669], Fake: [4.3090810012817382, 1.3250853791520325]) \n",
      "25400: D: 0.5901826620101929/1.4482214450836182 G: 0.8508278131484985 (Real: [4.1154025888442991, 1.2317332272608708], Fake: [3.9863523912429808, 1.2902131401216017]) \n",
      "25600: D: 1.4805951118469238/0.8998072147369385 G: 0.7450218796730042 (Real: [3.8995217368006707, 1.3883851437627404], Fake: [4.0352344012260435, 1.3561160103351464]) \n",
      "25800: D: 0.661322295665741/0.8378862142562866 G: 0.5829944014549255 (Real: [3.9772833824157714, 1.1908473205921728], Fake: [3.4819629955291749, 1.0483206243802419]) \n",
      "26000: D: 0.803491473197937/0.5590171813964844 G: 0.7747167944908142 (Real: [3.9589949294924738, 1.3728844489201104], Fake: [3.903793913125992, 1.1521612218038013]) \n",
      "26200: D: 0.6530004143714905/0.7433706521987915 G: 0.8974130153656006 (Real: [4.1973686343431469, 1.2604806091938121], Fake: [4.2455722332000736, 1.3112787963735497]) \n",
      "26400: D: 0.5761441588401794/0.808644711971283 G: 0.8108291029930115 (Real: [4.0083036193251607, 1.1791516037896101], Fake: [3.9256033039093019, 1.2523836891425653]) \n",
      "26600: D: 0.7101107835769653/0.8571808934211731 G: 0.5788459181785583 (Real: [3.8133162128925324, 1.3015836210141538], Fake: [3.7013107478618621, 1.29139270025176]) \n",
      "26800: D: 0.46884435415267944/0.47738707065582275 G: 0.7314632534980774 (Real: [4.3163873624801639, 1.4016214325338485], Fake: [4.2032443010807041, 1.1950251171761168]) \n",
      "27000: D: 0.641726016998291/0.6103999614715576 G: 0.6356748938560486 (Real: [3.9282069528102874, 1.2051894996118586], Fake: [4.2857716131210326, 1.2240078402935588]) \n",
      "27200: D: 0.9443284869194031/0.6096985936164856 G: 0.7252467274665833 (Real: [4.0054623478651044, 1.2820920446407549], Fake: [3.8713761174678805, 1.3518614419597572]) \n",
      "27400: D: 0.8762068748474121/0.6065651178359985 G: 0.4971504509449005 (Real: [4.2022226563841105, 1.2411642798727951], Fake: [4.0899653184413909, 1.2871247483812025]) \n",
      "27600: D: 0.7325016856193542/0.6891440153121948 G: 0.6877476572990417 (Real: [3.926754363179207, 1.3287464563378959], Fake: [4.2545166516304018, 1.2004674206092942]) \n",
      "27800: D: 0.6482959985733032/0.7770184874534607 G: 0.6079108715057373 (Real: [3.9568304049968721, 1.2711145417708369], Fake: [3.7615177094936372, 1.2990412196907584]) \n",
      "28000: D: 0.6171936988830566/0.7188903093338013 G: 0.7549570202827454 (Real: [3.7637928640842437, 1.2781262199633372], Fake: [4.2938047528266905, 1.2097818669317986]) \n",
      "28200: D: 0.6820794939994812/0.6813339591026306 G: 0.7046696543693542 (Real: [4.027429988384247, 1.0674108363903803], Fake: [3.9410288631916046, 1.0708864092859445]) \n",
      "28400: D: 0.6189024448394775/0.7769957780838013 G: 0.6350964307785034 (Real: [3.8845732259750365, 1.1269703437494991], Fake: [3.6496746122837065, 1.1805629219245475]) \n",
      "28600: D: 0.7548307180404663/0.6467130780220032 G: 0.7119991183280945 (Real: [4.0075461959838865, 1.3709542079072521], Fake: [4.5496706891059873, 1.2754076745424452]) \n",
      "28800: D: 0.739112138748169/0.7153136134147644 G: 0.569959282875061 (Real: [3.9744648456573488, 1.1701345696474956], Fake: [3.9285516703128813, 1.2955793328649958]) \n",
      "29000: D: 0.7533794641494751/0.6897853016853333 G: 0.642755925655365 (Real: [3.9468945658206938, 1.2094627652788421], Fake: [4.1563640809059139, 1.2030645465783929]) \n",
      "29200: D: 0.7162632942199707/0.6467553973197937 G: 0.6477739810943604 (Real: [3.7402125865221025, 1.2381442236458367], Fake: [3.7913349819183351, 1.2678517638115707]) \n",
      "29400: D: 0.6960283517837524/0.5294373631477356 G: 0.6798681020736694 (Real: [3.7535667729377749, 1.2211018991962463], Fake: [4.7678047966957093, 1.2760602877223317]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29600: D: 0.7010936141014099/0.7517508864402771 G: 0.6966797709465027 (Real: [3.9535645699501036, 1.1206787041972104], Fake: [3.3924783504009248, 1.2858441422878188]) \n",
      "29800: D: 0.7213623523712158/0.585443377494812 G: 0.8109933137893677 (Real: [4.0313089126348496, 1.3256953417746111], Fake: [4.4494288516044618, 1.2259823092119997]) \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for d_index in range(d_steps):\n",
    "        # 1. Train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))  # ones = true\n",
    "        d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))  # zeros = fake\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%s: D: %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
